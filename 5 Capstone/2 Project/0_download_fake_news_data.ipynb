{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download fake news data\n",
    "\n",
    "This notebook downloads the fake news data from kaggle and does some first analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# download required packages\n",
    "!pip install kaggle\n",
    "!pip install zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user parameters\n",
    "data_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kaggle_data(data_path, data_set, extract_zip=True):\n",
    "    \n",
    "    print('Download {} from kaggle.com...'.format(data_set), end='')\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_file(\n",
    "        dataset='clmentbisaillon/fake-and-real-news-dataset',\n",
    "        file_name=data_set,\n",
    "        path=data_path,\n",
    "        force=True\n",
    "    )\n",
    "\n",
    "    file_path = '{}/{}.zip'.format(data_path, data_set)\n",
    "    \n",
    "    if extract_zip:\n",
    "        zf = ZipFile(file_path)\n",
    "        zf.extractall(data_path)\n",
    "        zf.close()\n",
    "        !rm $file_path\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download fake news data\n",
    "download_kaggle_data(data_path, 'Fake.csv')\n",
    "download_kaggle_data(data_path, 'True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kaggle_data(data_path, data_set):\n",
    "    \n",
    "    file_path = '{}/{}'.format(data_path, data_set)\n",
    "    if os.path.exists(file_path):\n",
    "        \n",
    "        print('Import {}...'.format(data_set), end='')\n",
    "    \n",
    "        file_path = '{}/{}'.format(data_path, data_set)\n",
    "        imported_data = pd.read_csv(file_path)\n",
    "        !rm $file_path\n",
    "    \n",
    "        print('done')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        empty_dict = {'dummy_col_1': [3, 2, 1, 0], 'dummy_col_2': ['a', 'b', 'c', 'd']} # just some test data\n",
    "        imported_data = pd.DataFrame.from_dict(empty_dict)\n",
    "        print('{} does not exist. Please download again kaggle data.'.format(file_path))\n",
    "    \n",
    "    return imported_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "fake = read_kaggle_data(data_path, 'Fake.csv')\n",
    "true = read_kaggle_data(data_path, 'True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class \n",
    "fake['class'] = 1 # 1 = fake\n",
    "true['class'] = 0 # 0 = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake[['title', 'text', 'subject', 'date']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true[['title', 'text', 'subject', 'date']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that we have less unique values for title and text as counted values. This means several times the same titles and texts occur. I will remove not unique features once the text is processed further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data together and add classification\n",
    "original_document = pd.concat([true, fake])\n",
    "true = fake = None # to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_document.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_document[['title', 'text', 'subject', 'date']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_investigation(index, df, number_strings=0):\n",
    "    doc_class = df['class'].iloc[index]\n",
    "    title = df['title'].iloc[index]\n",
    "    text = df['text'].iloc[index]\n",
    "    if number_strings > 0:\n",
    "        text = text[:number_strings]\n",
    "        \n",
    "    print('Index {} - Class {} - {}\\n{}\\n'.format(index, doc_class, title, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_investigation(11010, original_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_from = 1\n",
    "select_to = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(select_from, select_to):\n",
    "    detailed_investigation(i, original_document, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First I will check what a regular text processing does, like removal of html tags, lower case but with no stemming. Title and text are put together for processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1112 \n",
    "- 284 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_text_processing(index, df):\n",
    "    \n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    df_title = df['title'].iloc[index]\n",
    "    df_text = df['text'].iloc[index]\n",
    "    text = '{} {}'.format(df_title, df_text)\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text() # remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower()) # convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words('english')] # Remove stopwords\n",
    "    text = ' '.join(words)\n",
    "    #words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_factbox(text):\n",
    "    text = re.sub('Factbox: Trump on Twitter', '', text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_twitter_intro(text):\n",
    "    text = re.sub('The following statements.*@realDonaldTrump', '', text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_reuters(text):\n",
    "    text = re.sub('.*\\(Reuters\\) -', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dates(text):\n",
    "    text = re.sub('[a-zA-Z]+ [0-9][0-9], [0-9][0-9][0-9][0-9]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets(text):    \n",
    "    text = re.sub('[\\(\\[].*?[\\)\\]]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):    \n",
    "    text = re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(index, df):\n",
    "    df_title = df['title'].iloc[index]    \n",
    "    df_text = df['text'].iloc[index]\n",
    "    text = remove_reuters(df_text)\n",
    "    text = '{} {}'.format(df_title, text)\n",
    "    text = remove_twitter_intro(text)\n",
    "    text = remove_factbox(text)\n",
    "    text = remove_dates(text)\n",
    "    text = remove_brackets(text)\n",
    "    text = remove_links(text)\n",
    "    \n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_investigation(284, original_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_text_processing(284, original_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
