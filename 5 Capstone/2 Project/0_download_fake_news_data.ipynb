{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download fake news data\n",
    "\n",
    "This notebook downloads the fake news data from kaggle and performs text processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install kaggle\n",
    "!pip install zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='bs4')\n",
    "import random\n",
    "import unittest\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate kaggle data\n",
    "\n",
    "Kaggle.com data is available on <code>clmentbisaillon/fake-and-real-news-dataset</code> and is named <code>True.csv</code> for the truthful news article and <code>Fake.csv</code> for the fake news article. A kaggle json object needs to be available in the .kaggle home directory (https://github.com/Kaggle/kaggle-api#api-credentials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kaggle_data(path, file, extract_zip):\n",
    "    \"\"\"\n",
    "    Download kaggle data from kaggle.com website.\n",
    "    \n",
    "    Args:\n",
    "    - path (str): Path where data is downloaded to.\n",
    "    - file (str): How file is named on kaggle.com website.\n",
    "    - extract_zip (boolean): Wheter data downloaded is zipped and must be extracted.\n",
    "    \n",
    "    Returns:\n",
    "    - none: Data is downloaded and extracted.\n",
    "    \"\"\"\n",
    "    print('Download {} from kaggle.com...'.format(file), end='')\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_file(        \n",
    "        dataset='clmentbisaillon/fake-and-real-news-dataset',\n",
    "        file_name=file,\n",
    "        path=path,\n",
    "        force=True\n",
    "    )\n",
    "\n",
    "    file_path = '{}/{}.zip'.format(path, file)\n",
    "    \n",
    "    if extract_zip:\n",
    "        zf = ZipFile(file_path)\n",
    "        zf.extractall(path)\n",
    "        zf.close()\n",
    "        !rm $file_path\n",
    "\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kaggle_data(path, file):\n",
    "    \"\"\"\n",
    "    Convert kaggle.com data from website to pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "    - path (str): Path where data is downloaded to.\n",
    "    - file (str): How file is named on kaggle.com website.\n",
    "    \n",
    "    Returns:\n",
    "    - imported_data (pandas dataframe): Converted pandas dataframe.\n",
    "    \"\"\"\n",
    "    file_path = '{}/{}'.format(path, file)\n",
    "    if os.path.exists(file_path):\n",
    "        \n",
    "        print('Import {}...'.format(file), end='')\n",
    "    \n",
    "        file_path = '{}/{}'.format(path, file)\n",
    "        imported_data = pd.read_csv(file_path)\n",
    "        !rm $file_path\n",
    "    \n",
    "        print('done')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        empty_dict = {'dummy_col_1': [3, 2, 1, 0], 'dummy_col_2': ['a', 'b', 'c', 'd']} # just some test data\n",
    "        imported_data = pd.DataFrame.from_dict(empty_dict)\n",
    "        print('{} does not exist. Please download again kaggle data.'.format(file_path))\n",
    "    \n",
    "    return imported_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kaggle_data(path, extract_zip=True):\n",
    "    \"\"\"\n",
    "    Generate kaggle.com data.\n",
    "    \n",
    "    Args:\n",
    "    - path (str): Path where data is downloaded to.\n",
    "    - extract_zip (boolean): Wheter data downloaded is zipped and must be extracted.\n",
    "    \n",
    "    Returns:\n",
    "    - corpus (pandas dataframe): Generated corpus.\n",
    "    \"\"\"\n",
    "    # download fake news data\n",
    "    download_kaggle_data(path, 'Fake.csv', extract_zip)\n",
    "    download_kaggle_data(path, 'True.csv', extract_zip)\n",
    "    \n",
    "    # import data\n",
    "    fake = read_kaggle_data(path, 'Fake.csv')\n",
    "    true = read_kaggle_data(path, 'True.csv')\n",
    "    \n",
    "    # add class \n",
    "    fake['class'] = 1 # 1 = fake\n",
    "    true['class'] = 0 # 0 = true\n",
    "    \n",
    "    # merge data together and add classification\n",
    "    corpus = pd.concat([true, fake])\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Fake.csv from kaggle.com...done\n",
      "Download True.csv from kaggle.com...done\n",
      "Import Fake.csv...done\n",
      "Import True.csv...done\n"
     ]
    }
   ],
   "source": [
    "corpus = generate_kaggle_data('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics about corpus\n",
    "\n",
    "We can see here that we have less unique values for title and text as counted values. This means several times the same titles and texts occur. I will remove not unique features once the text is processed further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  class  \n",
       "0  December 31, 2017       0  \n",
       "1  December 29, 2017       0  \n",
       "2  December 31, 2017       0  \n",
       "3  December 30, 2017       0  \n",
       "4  December 29, 2017       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44898</td>\n",
       "      <td>44898</td>\n",
       "      <td>44898</td>\n",
       "      <td>44898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>38729</td>\n",
       "      <td>38646</td>\n",
       "      <td>8</td>\n",
       "      <td>2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td></td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 20, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>627</td>\n",
       "      <td>11272</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title   text  \\\n",
       "count                                               44898  44898   \n",
       "unique                                              38729  38646   \n",
       "top     Factbox: Trump fills top jobs for his administ...          \n",
       "freq                                                   14    627   \n",
       "\n",
       "             subject                date  \n",
       "count          44898               44898  \n",
       "unique             8                2397  \n",
       "top     politicsNews  December 20, 2017   \n",
       "freq           11272                 182  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[['title', 'text', 'subject', 'date']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23481\n",
       "0    21417\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "Title and text are put together for processing. Several processing steps are performed in the following order:\n",
    "\n",
    "- Remove everything that is before (Reuters) in the text. Mostly, these are cities where the article is referenced to.\n",
    "- Remove twitter intro. In case tweets from the U.S. President are truthful, these articles start with \"The following statements...\" and stop with @realDonaldTrump. Everything between is excluded.\n",
    "- Remove \"Factbox: Trump on Twitter\" intro.\n",
    "- Remove everything that looks like a date, for example March 20, 1989, Mar 20, 1989 or just Mar 20 1989. Dates contain no information regarding classifiction and are therefore removed.\n",
    "- Remove everything between brackets [] or (). Often links are between brackets, therefore we just remove them.\n",
    "- Remove everything that looks like a link.\n",
    "- Remove text with source link.\n",
    "- Remove U.S.\n",
    "- Further cleaning of text like removal of digits, html tags, stopwords and stemming is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \"\"\"\n",
    "    Basic text processing:\n",
    "        -> HTML tag removal\n",
    "        -> Conversion to lower character\n",
    "        -> Split words between spaces\n",
    "        -> Stopwords removal\n",
    "        -> Stem words\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text() # remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text.lower()) # convert to lower case\n",
    "    words = text.split() # split string into words\n",
    "    words = [w for w in words if w not in stopwords.words('english')] # remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem \n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_us(text):\n",
    "    \"\"\"\n",
    "    Remove <<U.S.>> from text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('[uU].[sS].', '', text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_twitter_factbox(text):\n",
    "    \"\"\"\n",
    "    Remove <<Factbox: Trump on Twitter>> from text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('Factbox: Trump on Twitter', '', text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_twitter_intro(text):\n",
    "    \"\"\"\n",
    "    Remove everything between <<The following statements>> and <<@realDonaldTrump>> from text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('The following statements.*@realDonaldTrump', '', text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_reuters(text):\n",
    "    \"\"\"\n",
    "    Remove everything before and including (Reuters) from text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('.*\\(Reuters\\) -', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dates(text):\n",
    "    \"\"\"\n",
    "    Remove dates written as Mar(ch) 20(,) 1982 from text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('[a-zA-Z]+ [0-9]?[0-9],? [0-9][0-9][0-9][0-9]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_remove_dates():\n",
    "    \"\"\"\n",
    "    Performs a test of function remove_dates().\n",
    "    \"\"\"\n",
    "    text_1 = 'Shall we see each other March 5, 2017 again?'\n",
    "    result_text_1 = 'Shall we see each other  again?'\n",
    "    text_2 = 'Shall we see each other April 15, 2017 again?'\n",
    "    result_text_2 = 'Shall we see each other  again?'\n",
    "    text_3 = 'Shall we see each other May 5 2017 again?'\n",
    "    result_text_3 = 'Shall we see each other  again?'\n",
    "    text_4 = 'Shall we see each other January 17 again?'\n",
    "    result_text_4 = 'Shall we see each other January 17 again?'\n",
    "    assert remove_dates(text_1) == result_text_1, 'test_remove_dates: check of test 1 failed'\n",
    "    assert remove_dates(text_2) == result_text_2, 'test_remove_dates: check of test 2 failed'\n",
    "    assert remove_dates(text_3) == result_text_3, 'test_remove_dates: check of test 3 failed'\n",
    "    assert remove_dates(text_4) == result_text_4, 'test_remove_dates: check of test 4 failed'\n",
    "    print('all test_remove_dates tests passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets(text):   \n",
    "    \"\"\"\n",
    "    Remove brackets and text between brackets like () or [].\n",
    "\n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('[\\(\\[].*?[\\)\\]]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_source_link(text):\n",
    "    \"\"\"\n",
    "    Remove words source link from text (written in any combination of lower or upper case).\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('[sS][oO][uU][rR][cC][eE] [lL][iI][nN][kK]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(title, text):\n",
    "    \"\"\"\n",
    "    Execute text processing.\n",
    "    \n",
    "    Args:\n",
    "    - title (str): Title from news article.\n",
    "    - text (str): Text from news article.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Processed text.\n",
    "    \"\"\"\n",
    "    text = remove_reuters(text) # reuters part needs to be removed first before title is added\n",
    "    text = '{} {}'.format(title, text)\n",
    "    text = remove_twitter_intro(text)\n",
    "    text = remove_twitter_factbox(text)\n",
    "    text = remove_dates(text)\n",
    "    text = remove_brackets(text)\n",
    "    text = remove_links(text)\n",
    "    text = remove_source_link(text)\n",
    "    text = remove_us(text)\n",
    "    text = clear_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prossed_text_investigation(index, df, number_strings=0):\n",
    "    \"\"\"\n",
    "    Analyze news article from processed text.\n",
    "    \n",
    "    Args:\n",
    "    - index (int): Index to be checked.\n",
    "    - df (pandas dataframe): Corpus.\n",
    "    - number_strings (int): Number of strings to be checked from processed news article.\n",
    "    \n",
    "    Returns:\n",
    "    - none: Prints the processd news article.\n",
    "    \"\"\"\n",
    "    assert number_strings >= 0, 'number_strings must be 0 or positive' \n",
    "    \n",
    "    doc_class = df['class'].iloc[index]\n",
    "    title = df['title'].iloc[index]\n",
    "    text = df['text'].iloc[index]\n",
    "    text = text_processing(title, text)\n",
    "    if number_strings > 0:\n",
    "        text = text[:number_strings]\n",
    "        \n",
    "    print('INDEX {} - CLASS {} - {}\\n'.format(index, doc_class, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprossed_text_investigation(index, df, number_strings=0):\n",
    "    \"\"\"\n",
    "    Analyze news article from unprocessed text.\n",
    "    \n",
    "    Args:\n",
    "    - index (int): Index to be checked.\n",
    "    - df (pandas dataframe): Corpus.\n",
    "    - number_strings (int): Number of strings to be checked from unprocessed news article.\n",
    "    \n",
    "    Returns:\n",
    "    - none: Prints the unprocessed news article.\n",
    "    \"\"\"\n",
    "    assert number_strings >= 0, 'number_strings must be 0 or positive'   \n",
    "    \n",
    "    doc_class = df['class'].iloc[index]\n",
    "    title = df['title'].iloc[index]\n",
    "    text = df['text'].iloc[index]\n",
    "    if number_strings > 0:\n",
    "        text = text[:number_strings]\n",
    "        \n",
    "    print('INDEX {} - CLASS {} - {} {}\\n'.format(index, doc_class, title, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define unit test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_remove_us():\n",
    "    \"\"\"\n",
    "    Performs a test of function remove_us().\n",
    "    \"\"\"\n",
    "    text_1 = 'The U.S. President or the u.s. President or even U.s. President'\n",
    "    result_text_1 = 'The  President or the  President or even  President'\n",
    "    assert remove_us(text_1) == result_text_1, 'test_remove_us: check of test 1 failed'\n",
    "    print('all test_remove_us tests passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_remove_brackets():\n",
    "    \"\"\"\n",
    "    Performs a test of function remove_brackets().\n",
    "    \"\"\"\n",
    "    text_1 = '[VIDEO], [video], (other stuff), but not this'\n",
    "    result_text_1 = ', , , but not this'\n",
    "    assert remove_brackets(text_1) == result_text_1, 'test_remove_brackets: check of test 1 failed'\n",
    "    print('all test_remove_brackets tests passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_remove_source_link():\n",
    "    \"\"\"\n",
    "    Performs a test of function remove_source_link().\n",
    "    \"\"\"\n",
    "    text_1 = 'All kind of source link or SOURCE LINK or Source Link or just link'\n",
    "    result_text_1 = 'All kind of  or  or  or just link'  \n",
    "    assert remove_source_link(text_1) == result_text_1, 'test_remove_source_link: check of test 1 failed'\n",
    "    print('all test_remove_source_link tests passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_remove_links():\n",
    "    \"\"\"\n",
    "    Performs a test of function remove_links().\n",
    "    \"\"\"\n",
    "    text_1 = 'This text contains some tiny urls such as (bit.ly/2jBh4LU) and another (bit.ly/2jpEXYR) or also ' + \\\n",
    "             'normal URLs such as https://www.ubs.com/ch/de.html or http://www.ubs.com/ch/de.html'\n",
    "    result_text_1 = 'This text contains some tiny urls such as and another or also normal URLs such as or'  \n",
    "    text_2 = 'In another text, we use tiny urls without brackets like bit.ly/2jBh4LU and combining with longer ' + \\\n",
    "             'URLs like https://stackoverflow.com/questions/9043820/regex-to-match-words-of-a-certain-length ' + \\\n",
    "             'but it should not stop at the end but continue'\n",
    "    result_text_2 = 'In another text, we use tiny urls without brackets like and combining with longer ' + \\\n",
    "                    'URLs like but it should not stop at the end but continue'\n",
    "    text_3 = 'But is it also a problem when there is a slash at the end of the URL: https://stackoverflow.com/ ?'\n",
    "    result_text_3 = 'But is it also a problem when there is a slash at the end of the URL: ?'\n",
    "    assert remove_links(text_1) == result_text_1, 'test_remove_links: check of test 1 failed'\n",
    "    assert remove_links(text_2) == result_text_2, 'test_remove_links: check of test 2 failed'\n",
    "    assert remove_links(text_3) == result_text_3, 'test_remove_links: check of test 3 failed'\n",
    "    print('all test_remove_links tests passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text): \n",
    "    \"\"\"\n",
    "    Remove everything that looks like a link from text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): Text to be cleared.\n",
    "    \n",
    "    Returns:\n",
    "    - text (str): Cleared text.\n",
    "    \"\"\"\n",
    "    text = re.sub('(?:\\\\s)[^\\\\s\\\\.]*\\\\.[^\\\\s]+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test of text processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_unit_tests():\n",
    "    \"\"\"\n",
    "    Performs all unit tests in one call.\n",
    "    \"\"\"\n",
    "    test_remove_us()\n",
    "    test_remove_dates()\n",
    "    test_remove_brackets()\n",
    "    test_remove_source_link()\n",
    "    test_remove_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all test_remove_us tests passed\n",
      "all test_remove_dates tests passed\n",
      "all test_remove_brackets tests passed\n",
      "all test_remove_source_link tests passed\n",
      "all test_remove_links tests passed\n"
     ]
    }
   ],
   "source": [
    "perform_unit_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate before and after text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_and_after_check(df, check_index):\n",
    "    \"\"\"\n",
    "    Performs a comprison between article before and after text processing.\n",
    "    \n",
    "    Args:\n",
    "    - df (pandas dataframe): Corpus.\n",
    "    - check_index (int): Index from corpus dataframe where comparison is applied to.\n",
    "    \"\"\"\n",
    "    unprossed_text_investigation(check_index, df)\n",
    "    prossed_text_investigation(check_index, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX 23876 - CLASS 1 -  Republicans Attack NASA For Trying To Save Earth Instead Of Putting Space First Republicans don t seem to understand that Earth is the planet we live on.Donald Trump and his Republicans supporters in Congress are taking aim at any agency that studies climate change.Climate change has had a devastating impact on our planet. The ice sheets are melting as an unprecedented rate and sea level rise threatens to drown our coastlines, which includes Trump s Mar-a-Lago resort at Palm Beach, Florida.Furthermore, weather patterns have become more unpredictable and we are seeing more instances of major disastrous hurricanes, wildfires, droughts, etc Whether Republicans like it or not, humans have been the driving force behind climate change, and it will get even worse since Trump is giving oil, gas, coal and chemical companies the freedom to pollute more than ever before. Soon, our cities will be choked by smog and our waterways will be poisoned as global temperatures continue to rise because of all the carbon we pump into the air.That s why NASA s Earth Science Division exists to track and study climate change in order to find ways to slow it down or stop it and reverse it so that future generations of the human race can continue living on the planet. After all, we only have one planet to live on.But Republicans like Rep. Lamar Smith think NASA should make space their top priority even though Earth is far more important because without it we wouldn t be alive, and thus, unable to explore the universe.Smith wants to cut Earth Science from NASA s budget in an effort to stop the science agency from studying climate change. By rebalancing, I d like for more funds to go into space exploration; we re not going to zero out earth sciences,  Smith said.  Our weather satellites have been an immense help, for example, and that s from NASA, but I d like for us to remember what our priorities are, and there are another dozen agencies that study earth science and climate change, and they can continue to do that. Meanwhile, we only have one agency that engages in space exploration, and they need every dollar they can muster for space exploration. Actually, other agencies can t continue to study climate change because Trump and his team are preventing them from doing so. That, and the fact that many of these agencies do not have the budget that NASA has to study climate change effectively pretty much means Republicans are making it their mission to gut climate change research.Before taking office, Trump demanded that the Energy Department send a list of employees and labs connected to studying climate change. And Trump s nomination of Rick Perry to head the Energy Department and anti-science Oklahoma Republican Scott Pruitt make it clear that climate change research is about to be disappeared, which is why scientists are working overtime to download all information gathered on climate change before Trump s government deletes it.Also, saving the Earth should be our top priority right now. Space can wait and NASA is already preparing to eventually send people to Mars, so it s not like NASA is incapable of doing both. But Smith wants NASA to stop studying a man-made phenomenon that will destroy us if we don t do something to stop it all because he doesn t want to anger his oil and gas industry masters.This planet is facing an impending disaster the likes of which we have never seen before. Ignoring it won t make it go away and not preparing for the effects will result in a massive loss of life and the destruction of property. And Republicans will be the ones to blame.Featured image via NASA\n",
      "\n",
      "INDEX 23876 - CLASS 1 - republican attack nasa tri save earth instead put space first republican seem understand earth planet live trump republican support congress take aim agenc studi climat chang devast impact planet ice sheet melt unpreced rate sea level rise threaten drown coastlin includ trump mar lago resort palm beach weather pattern becom unpredict see instanc major disastr hurrican wildfir drought etc whether republican like human drive forc behind climat chang get even wors sinc trump give oil ga coal chemic compani freedom pollut ever soon citi choke smog waterway poison global temperatur continu rise carbon pump nasa earth scienc divis exist track studi climat chang order find way slow stop revers futur gener human race continu live planet one planet live republican like rep lamar smith think nasa make space top prioriti even though earth far import without aliv thu unabl explor want cut earth scienc nasa budget effort stop scienc agenc studi climat chang rebalanc like fund go space explor go zero earth scienc smith said weather satellit immens help exampl nasa like us rememb prioriti anoth dozen agenc studi earth scienc climat chang continu meanwhil one agenc engag space explor need everi dollar muster space explor actual agenc continu studi climat chang trump team prevent fact mani agenc budget nasa studi climat chang effect pretti much mean republican make mission gut climat chang take offic trump demand energi depart send list employe lab connect studi climat chang trump nomin rick perri head energi depart anti scienc oklahoma republican scott pruitt make clear climat chang research disappear scientist work overtim download inform gather climat chang trump govern delet save earth top prioriti right space wait nasa alreadi prepar eventu send peopl mar like nasa incap smith want nasa stop studi man made phenomenon destroy us someth stop want anger oil ga industri planet face impend disast like never seen ignor make go away prepar effect result massiv loss life destruct properti republican one imag via nasa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "before_and_after_check(corpus, 23876)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a clean dataset \n",
    "\n",
    "We also need to make sure to remove duplicates! Furthermore, data resampling is performed for training, test and validation dataset extraction in a further step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restruct_text(df):\n",
    "    \"\"\"\n",
    "    Performs text processing.\n",
    "    \n",
    "    Args:\n",
    "    - df (pandas dataframe): Corpus where text processing should be applied to (corpus must contain \n",
    "    feature 'title' and 'text').\n",
    "    \n",
    "    Returns:\n",
    "    -df (pandas dataframe): Text processed corpus (processed text is available in feature 'processed_text').\n",
    "    \"\"\"\n",
    "    nrow_data = len(df.index)\n",
    "    print('{} entries to process'.format(nrow_data))\n",
    "    iteration = 0\n",
    "    start_time = time.time()\n",
    "    for i in df.index:\n",
    "        title = df['title'].iloc[i]\n",
    "        text = df['text'].iloc[i]\n",
    "        iteration += 1\n",
    "        if iteration % 100 is 0:\n",
    "            time_now = time.time()\n",
    "            time_diff = time_now - start_time\n",
    "            total_time_estimated = nrow_data / iteration * time_diff\n",
    "            time_remaining = total_time_estimated - time_diff\n",
    "            print('Iterate {}/{} (time used: {:.0f}s, remaining time: {:.0f}s)'.\n",
    "                  format(iteration, nrow_data, time_diff, time_remaining))\n",
    "            \n",
    "        df.loc[i, 'processed_text'] = text_processing(title, text)\n",
    "        \n",
    "    print('done')\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_corpus(df, set_seed):\n",
    "    \"\"\"\n",
    "    Resamples the corpus.\n",
    "    \n",
    "    Args:\n",
    "    - df (pandas dataframe): Corpus to be resampled.\n",
    "    - set_seed (int): Seed for the random resampling.\n",
    "    \n",
    "    Returns:\n",
    "    - df (pandas dataframe): Resampled corpus.\n",
    "    \"\"\"\n",
    "    nrow_data = len(df.index)\n",
    "    random.seed(set_seed)\n",
    "    sample_index = random.sample(range(nrow_data), nrow_data)\n",
    "    df = df.iloc[sample_index]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_corpus(df, path, file, set_seed=1, corpus_size=None):\n",
    "    \"\"\"\n",
    "    Resamples corpus, performs text processing and saves the corpus to the file system.\n",
    "    \n",
    "    Args:\n",
    "    - df (pandas dataframe): Corpus to be resampled, processed and saved.\n",
    "    - path (str): Path where the edited corpus is saved to.\n",
    "    - file (str): Filename of the corpus to be saved.\n",
    "    - set_seed (int): Seed for the random resampling.\n",
    "    - corpus_size (int): Selected size of the corpus to be processed.\n",
    "    \n",
    "    Returns:\n",
    "    - none: Saves the edited corpus to the file system.\n",
    "    \"\"\"\n",
    "    \n",
    "    # resample corpus\n",
    "    print('resample corpus...' , end='')\n",
    "    df = resample_corpus(df, set_seed)\n",
    "    print('done')\n",
    "    \n",
    "    # cut corpus size (if used)\n",
    "    if corpus_size is not None:\n",
    "        df_cut = df.iloc[:corpus_size].copy()\n",
    "    else:\n",
    "        df_cut = df.copy()\n",
    "        \n",
    "    # start text processing\n",
    "    df_proc = restruct_text(df_cut)\n",
    "    \n",
    "    # keep only class and processed_text, \n",
    "    df_save = df_proc[['class', 'processed_text']].copy()\n",
    "        \n",
    "    # export, without duplicates\n",
    "    df_save.drop_duplicates(inplace=True)\n",
    "    df_save.to_csv('{}/{}'.format(path, file), index=False)\n",
    "\n",
    "    print('{} saved'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_corpus(corpus, 'data', 'corpus-44898.csv', 4, 44898)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
