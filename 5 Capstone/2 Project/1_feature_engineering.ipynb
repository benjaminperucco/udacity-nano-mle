{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "data_path = 'data'\n",
    "data_set = 'clean_document.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = pd.read_csv('{}/{}'.format(data_path, data_set))\n",
    "document.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_vocabulary(dictionary):\n",
    "    zipped_dictionary = zip(dictionary.values(), dictionary.keys())\n",
    "    sorted_zipped_dictionary = sorted(zipped_dictionary, reverse=True)\n",
    "    return sorted_zipped_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_term_frequency(X):\n",
    "    term_frequency_list = []\n",
    "    for array in X:\n",
    "        if array.sum() > 0:\n",
    "            term_frequency_list.append(array / array.sum())\n",
    "        else:\n",
    "            term_frequency_list.append(array)\n",
    "    \n",
    "    numpy_frequency = np.array(term_frequency_list)\n",
    "    return numpy_frequency        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(df, feature_size):\n",
    "    corpus = df['processed_text'].values\n",
    "    vectorizer = CountVectorizer(max_features=feature_size)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    sorted_vocabulary = order_vocabulary(vectorizer.vocabulary_) # sort importance of words\n",
    "    feature_vocabulary = vectorizer.get_feature_names() # feature order\n",
    "    term_frequency = calculate_term_frequency(X.toarray())\n",
    "    return sorted_vocabulary, feature_vocabulary, term_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocabulary, feature_vocabulary, term_frequency = build_vocabulary(document, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19, 'year'),\n",
       " (18, 'would'),\n",
       " (17, 'trump'),\n",
       " (16, 'told'),\n",
       " (15, 'state'),\n",
       " (14, 'say'),\n",
       " (13, 'said'),\n",
       " (12, 'republican'),\n",
       " (11, 'report'),\n",
       " (10, 'presid'),\n",
       " (9, 'peopl'),\n",
       " (8, 'one'),\n",
       " (7, 'new'),\n",
       " (6, 'like'),\n",
       " (5, 'law'),\n",
       " (4, 'hous'),\n",
       " (3, 'govern'),\n",
       " (2, 'donald'),\n",
       " (1, 'clinton'),\n",
       " (0, 'also')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['also',\n",
       " 'clinton',\n",
       " 'donald',\n",
       " 'govern',\n",
       " 'hous',\n",
       " 'law',\n",
       " 'like',\n",
       " 'new',\n",
       " 'one',\n",
       " 'peopl',\n",
       " 'presid',\n",
       " 'report',\n",
       " 'republican',\n",
       " 'said',\n",
       " 'say',\n",
       " 'state',\n",
       " 'told',\n",
       " 'trump',\n",
       " 'would',\n",
       " 'year']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03030303, 0.        , 0.03030303, ..., 0.12121212, 0.15151515,\n",
       "        0.12121212],\n",
       "       [0.        , 0.        , 0.0625    , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07142857, 0.        , 0.        , ..., 0.        , 0.07142857,\n",
       "        0.07142857],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.04545455,\n",
       "        0.04545455],\n",
       "       [0.        , 0.        , 0.03225806, ..., 0.35483871, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.09677419,\n",
       "        0.03225806]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
