{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_features(values, keys):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    summed_values = values.sum(axis=0)\n",
    "    zipped_dictionary = zip(summed_values, keys)\n",
    "    sorted_zipped_dictionary = sorted(zipped_dictionary, reverse=True)\n",
    "    return sorted_zipped_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(df, feature_size, n_gram_size):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    corpus = df['processed_text'].values\n",
    "    vectorizer = CountVectorizer(max_features=feature_size, ngram_range=(n_gram_size, n_gram_size))\n",
    "    feature_matrix = vectorizer.fit_transform(corpus)\n",
    "    feature_vocabulary = vectorizer.get_feature_names() # feature order\n",
    "    return feature_vocabulary, feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_statistics(df, select_class, feature_size, n_gram_size):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    selected_df = df.loc[df['class'] == select_class]\n",
    "    vocabulary, matrix = build_vocabulary(selected_df, feature_size, n_gram_size)\n",
    "    statistics = count_features(matrix, vocabulary)\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tuples(list_1, list_2):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    dict_1 = {}\n",
    "    for detail in list_1:\n",
    "        tmp_dict = {detail[1]: detail[0]}\n",
    "        dict_1.update(tmp_dict)\n",
    "    \n",
    "    dict_2 = {}\n",
    "    for detail in list_2:\n",
    "        tmp_dict = {detail[1]: detail[0]}\n",
    "        dict_2.update(tmp_dict)\n",
    "    \n",
    "    \n",
    "    return dict_1, dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dicts(dict_1, dict_2):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    summed_dict = dict_2\n",
    "    for key in dict_1:\n",
    "        if key in dict_2:\n",
    "            summed_dict[key] = dict_2[key] + dict_1[key]\n",
    "        else:\n",
    "            summed_dict.update({key: dict_1[key]}) \n",
    "    \n",
    "    return summed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_dict(from_dict, add_class):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    import_dict = {'key': list(from_dict.keys()), 'value': list(from_dict.values())}\n",
    "    df = pd.DataFrame.from_dict(import_dict)\n",
    "    df['class'] = add_class\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_vocabulary(df, feature_size, n_gram_size):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    # create statistics\n",
    "    n_gram_0 = ngram_statistics(df, 0, feature_size, n_gram_size)\n",
    "    n_gram_1 = ngram_statistics(df, 1, feature_size, n_gram_size)\n",
    "    \n",
    "    # create dicts from tuples\n",
    "    dict_0, dict_1 = split_tuples(n_gram_0, n_gram_1)\n",
    "    \n",
    "    # create dataframes\n",
    "    df_0 = create_df_from_dict(dict_0, 0)\n",
    "    df_1 = create_df_from_dict(dict_1, 1)\n",
    "    \n",
    "    # merge dataframes\n",
    "    df = pd.concat([df_0, df_1], axis=0)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine 20 most used 1-gram per class and make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import corpus data\n",
    "corpus = pd.read_csv('{}/{}'.format('data', 'corpus-44898.csv'))\n",
    "corpus.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_merged_vocabulary(corpus, 20, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(df, x, y, group, output):\n",
    "    \"\"\"\n",
    "    tbd.\n",
    "    \"\"\"\n",
    "    %matplotlib inline\n",
    "    sns.set_style(style='whitegrid')\n",
    "    g = sns.catplot(\n",
    "        data=df, kind='bar',\n",
    "        x=x, y=y, hue=group, \n",
    "        palette='dark', alpha=.7, height=8.27, aspect=11.7/8.27\n",
    "    )\n",
    "    g.set_xticklabels(rotation=90)\n",
    "    g.savefig(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(results, 'key', 'value', 'class', 'output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
